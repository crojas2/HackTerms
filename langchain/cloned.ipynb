{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This version uses Milvus through Docker Compose so you must have Docker installed to run this notebook (Milvus is spun up via `docker compose up -d` as shown in the block below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install -qU pymilvus langchain sentence-transformers tiktoken octoai-sdk openai\n",
    "# !docker compose up -d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "# %env OCTOAI_API_KEY = 'alnvnipa4gjj'\n",
    "# %env OCTOAI_API_TOKEN = 'eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCIsImtpZCI6IjNkMjMzOTQ5In0.eyJzdWIiOiIwNTA3Y2IwOC03ODM2LTRhMTItOTA2NS0wMjczYTUxMjI5OWUiLCJ0eXBlIjoidXNlckFjY2Vzc1Rva2VuIiwidGVuYW50SWQiOiIxODg5MTdhYS05OTgyLTRkYmUtOGM2OC1lZGU2NzZjNDMzYTgiLCJ1c2VySWQiOiI5MzRiMWI2OC0yYTY3LTQwYjYtOGY5OS05N2IzMzgzZWE4YmMiLCJhcHBsaWNhdGlvbklkIjoiYTkyNmZlYmQtMjFlYS00ODdiLTg1ZjUtMzQ5NDA5N2VjODMzIiwicm9sZXMiOlsiRkVUQ0gtUk9MRVMtQlktQVBJIl0sInBlcm1pc3Npb25zIjpbIkZFVENILVBFUk1JU1NJT05TLUJZLUFQSSJdLCJhdWQiOiIzZDIzMzk0OS1hMmZiLTRhYjAtYjdlYy00NmY2MjU1YzUxMGUiLCJpc3MiOiJodHRwczovL2lkZW50aXR5Lm9jdG9tbC5haSIsImlhdCI6MTcxNDkzMDQ0Mn0.SoasYiHlD-7cX4ubQk5Um7RwdyHD_NUs74T33aGruTsR6Svaaoecr8uxWHw5QbJH6wUmYy1--ulhKUgABfd6RnN610d5C0lEMTKaF7bDcg_yI-B4i67d9E5N2zJck1yeDIW9swJcLfEWS6XYu2cE34wrP__R1ss8OxA7OwoMBnkpOaMya9u11eJaMyIPidavqol5byssvpozn-gM3iEOogVPaKP5MFXyi-27wmosQ6frgTJYyQ1CpOs2-XuKEwko6MJFiK1ezr_TiBZ3LH7uYO1m2FbtrltrEQQCR9ZeWUZJdNjRLdkZqhA3-chJQR6DMwfO0eq2MYlGJ4lbHMjD4w'\n",
    "\n",
    "\n",
    "OCTOAI_API_TOKEN = os.environ[\"OCTOAI_API_TOKEN\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sangwonan/hackerthon/.venv/lib/python3.12/site-packages/langchain_core/utils/utils.py:159: UserWarning: WARNING! model is not default parameter.\n",
      "                model was transferred to model_kwargs.\n",
      "                Please confirm that model is what you intended.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms.octoai_endpoint import OctoAIEndpoint\n",
    "llm = OctoAIEndpoint(\n",
    "        model=\"mixtral-8x7b-instruct-fp16\",\n",
    "        max_tokens=200,\n",
    "        presence_penalty=0,\n",
    "        temperature=0.1,\n",
    "        top_p=0.9,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import OctoAIEmbeddings\n",
    "from langchain_community.vectorstores import Milvus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OctoAIEmbeddings(endpoint_url=\"https://text.octoai.run/v1/embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(\"../city_data\")\n",
    "# files = os.listdir(\"../terms_and_condition_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Signal.txt',\n",
       " 'Epic Games.txt',\n",
       " 'moBILET.txt',\n",
       " 'Nike.txt',\n",
       " 'EliteSingles.txt',\n",
       " 'Baidu AI Cloud.txt',\n",
       " 'Tidal.txt',\n",
       " 'Glovo.txt',\n",
       " 'Viber.txt',\n",
       " 'GG.txt',\n",
       " 'Tinder.txt',\n",
       " 'vod.mdag.pl.txt',\n",
       " 'Vinted.txt',\n",
       " 'Meta.txt',\n",
       " 'Dropbox.txt',\n",
       " 'Microsoft.txt',\n",
       " 'Adobe.txt',\n",
       " 'DingTalk.txt',\n",
       " 'KAYAK.txt',\n",
       " 'Pyszne.pl.txt',\n",
       " 'Maya.txt',\n",
       " 'Steam.txt',\n",
       " 'TripAdvisor.txt',\n",
       " 'OVH.txt',\n",
       " 'Strava.txt',\n",
       " 'DoorDash.txt',\n",
       " 'FollowMyHealth.txt',\n",
       " 'PAYBACK.txt',\n",
       " 'Spotify.txt',\n",
       " 'Cisco.txt',\n",
       " 'Blik.txt',\n",
       " 'Toggl.txt',\n",
       " 'Supercell.txt',\n",
       " 'Hotels.com.txt',\n",
       " 'Telegram.txt',\n",
       " 'Gett.txt',\n",
       " 'Niantic.txt',\n",
       " 'Bolt.txt',\n",
       " 'Zenly.txt',\n",
       " 'HBO GO.txt',\n",
       " 'Zalando.txt',\n",
       " 'Booking.com.txt',\n",
       " 'Krakowskie Smaki.txt',\n",
       " 'ABEMA.txt',\n",
       " 'Aliexpress.txt',\n",
       " 'Zoom.txt',\n",
       " 'Twitch.txt',\n",
       " 'YouTube.txt',\n",
       " 'FineDine.txt',\n",
       " 'Oktawave.txt',\n",
       " 'Yahoo.txt',\n",
       " 'BlaBlaCar.txt',\n",
       " 'MyFitnessPal.txt',\n",
       " 'Line.txt',\n",
       " 'Crypto.com.txt',\n",
       " 'iTaxi.txt',\n",
       " 'Pinterest.txt',\n",
       " 'Google.txt',\n",
       " 'MyTaxi.txt',\n",
       " 'Ubisoft.txt',\n",
       " 'Sympatia.pl.txt',\n",
       " 'Sleep Cycle.txt',\n",
       " 'MultiSport.txt',\n",
       " 'Amazon.txt',\n",
       " 'PayPal.txt',\n",
       " 'Lyft.txt',\n",
       " 'PayPay.txt',\n",
       " 'adidas.txt',\n",
       " 'Quora.txt',\n",
       " 'Snapchat.txt',\n",
       " 'TikTok.txt',\n",
       " 'Netflix.txt',\n",
       " 'Apple.txt',\n",
       " 'iCloud.txt',\n",
       " 'ZnanyLekarz.txt',\n",
       " 'SQUARE ENIX.txt',\n",
       " 'Keep.txt',\n",
       " 'SHEIN.txt',\n",
       " 'Allegro.txt',\n",
       " 'LetyShops.txt',\n",
       " 'ZipRecruiter.txt',\n",
       " 'Yanosik.txt',\n",
       " 'Dailymotion.txt',\n",
       " 'Twitter.txt',\n",
       " 'Hotels.txt',\n",
       " 'The Witcher - Monster Slayer.txt',\n",
       " 'Discord.txt',\n",
       " 'LinkedIn.txt',\n",
       " 'Slack.txt',\n",
       " 'Skyscanner.txt',\n",
       " 'Match.com.txt',\n",
       " 'Uber.txt',\n",
       " 'Reddit.txt',\n",
       " 'trivago.txt',\n",
       " 'Wolt.txt',\n",
       " 'Pracuj.pl.txt',\n",
       " 'eToro.txt',\n",
       " 'Badoo.txt',\n",
       " 'ALBICLA.txt',\n",
       " 'EA.txt',\n",
       " 'Evernote.txt']"
      ]
     },
     "execution_count": 656,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_texts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 556, which is longer than the specified 512\n",
      "Created a chunk of size 684, which is longer than the specified 512\n",
      "Created a chunk of size 529, which is longer than the specified 512\n",
      "Created a chunk of size 858, which is longer than the specified 512\n",
      "Created a chunk of size 545, which is longer than the specified 512\n",
      "Created a chunk of size 583, which is longer than the specified 512\n",
      "Created a chunk of size 647, which is longer than the specified 512\n",
      "Created a chunk of size 582, which is longer than the specified 512\n",
      "Created a chunk of size 548, which is longer than the specified 512\n",
      "Created a chunk of size 561, which is longer than the specified 512\n",
      "Created a chunk of size 545, which is longer than the specified 512\n",
      "Created a chunk of size 607, which is longer than the specified 512\n",
      "Created a chunk of size 865, which is longer than the specified 512\n",
      "Created a chunk of size 616, which is longer than the specified 512\n",
      "Created a chunk of size 1649, which is longer than the specified 512\n",
      "Created a chunk of size 645, which is longer than the specified 512\n",
      "Created a chunk of size 528, which is longer than the specified 512\n",
      "Created a chunk of size 538, which is longer than the specified 512\n",
      "Created a chunk of size 853, which is longer than the specified 512\n",
      "Created a chunk of size 555, which is longer than the specified 512\n",
      "Created a chunk of size 531, which is longer than the specified 512\n",
      "Created a chunk of size 586, which is longer than the specified 512\n",
      "Created a chunk of size 526, which is longer than the specified 512\n",
      "Created a chunk of size 657, which is longer than the specified 512\n",
      "Created a chunk of size 617, which is longer than the specified 512\n",
      "Created a chunk of size 637, which is longer than the specified 512\n",
      "Created a chunk of size 957, which is longer than the specified 512\n",
      "Created a chunk of size 924, which is longer than the specified 512\n",
      "Created a chunk of size 815, which is longer than the specified 512\n",
      "Created a chunk of size 650, which is longer than the specified 512\n",
      "Created a chunk of size 515, which is longer than the specified 512\n",
      "Created a chunk of size 581, which is longer than the specified 512\n",
      "Created a chunk of size 516, which is longer than the specified 512\n",
      "Created a chunk of size 560, which is longer than the specified 512\n",
      "Created a chunk of size 520, which is longer than the specified 512\n",
      "Created a chunk of size 561, which is longer than the specified 512\n",
      "Created a chunk of size 687, which is longer than the specified 512\n",
      "Created a chunk of size 513, which is longer than the specified 512\n"
     ]
    }
   ],
   "source": [
    "for file in files:\n",
    "    with open(f\"../city_data/{file}\") as f:\n",
    "        file_text = f.read()\n",
    "    text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "        chunk_size=512, chunk_overlap=64, separator='\\n'\n",
    "    )\n",
    "    \n",
    "    texts = text_splitter.split_text(file_text)\n",
    "    # texts = file_text.split('\\n')\n",
    "    # print(texts)\n",
    "    for i, chunked_text in enumerate(texts):\n",
    "        file_texts.append(Document(page_content=chunked_text, \n",
    "                metadata={\"doc_title\": file.split(\".\")[0], \"chunk_num\": i}))\n",
    "        # print(len(chunked_text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the first run\n",
    "# # # \n",
    "# vector_store = Milvus.from_documents(\n",
    "#     file_texts,\n",
    "#     embedding=embeddings,\n",
    "#     connection_args={\"host\": \"localhost\", \"port\": 19530},\n",
    "#     collection_name=\"city_data\"\n",
    "# )\n",
    "\n",
    "# if you already have the data you need stored in Milvus\n",
    "# vector_store = Milvus(\n",
    "#     embedding_function=embeddings,\n",
    "#     connection_args={\"host\": \"localhost\", \"port\": 19530},\n",
    "#     collection_name=\"city_data\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "template=\"\"\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
    "Question: {question} \n",
    "Context: {context} \n",
    "Answer:\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [],
   "source": [
    "response1 = chain.invoke(\"Summarize privacy terms for Adobe\")\n",
    "response2 = chain.invoke(\"I am going to use Youtube, Does Youtube have any rights to use my video?\")\n",
    "response3 = chain.invoke(\"Can you smmarize service terms for Yahoo?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Yahoo's service terms include a liability limit for disputes, which is the amount paid for the services. Users must not violate laws or the Community Guidelines, and should be of the minimum age to use the services. Fee-based services require accurate billing information and are subject to third-party terms.\""
      ]
     },
     "execution_count": 664,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Yes, when you upload a video to YouTube, you grant them a license to use your video for operating, promoting, and improving their service. This includes the right to reproduce, distribute, modify, display, and perform your video. Other users also receive a license to access your video through the Service. These licenses terminate when you remove your video, except where the law requires otherwise.'"
      ]
     },
     "execution_count": 665,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
